{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes Project\n",
    "#### Team:  Neha Boi, Liam Nguyen\n",
    "#### CECS 550"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "FILE_NAME = \"diabetes.csv\"\n",
    "TRAIN_TEST_RATIO = 0.8 \n",
    "TN = 0\n",
    "FP = 0 \n",
    "FN = 0\n",
    "TP = 0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        0      1     2     3      4     5      6     7    8\n",
      "0     1.0   85.0  66.0  29.0    0.0  26.6  0.351  31.0  0.0\n",
      "1     0.0  137.0  40.0  35.0  168.0  43.1  2.288  33.0  1.0\n",
      "2     8.0  125.0  96.0   0.0    0.0   0.0  0.232  54.0  1.0\n",
      "3    10.0  139.0  80.0   0.0    0.0  27.1  1.441  57.0  0.0\n",
      "4     1.0  189.0  60.0  23.0  846.0  30.1  0.398  59.0  1.0\n",
      "..    ...    ...   ...   ...    ...   ...    ...   ...  ...\n",
      "249   9.0   89.0  62.0   0.0    0.0  22.5  0.142  33.0  0.0\n",
      "250  10.0  101.0  76.0  48.0  180.0  32.9  0.171  63.0  0.0\n",
      "251   5.0  121.0  72.0  23.0  112.0  26.2  0.245  30.0  0.0\n",
      "252   1.0  126.0  60.0   0.0    0.0  30.1  0.349  47.0  1.0\n",
      "253   1.0   93.0  70.0  31.0    0.0  30.4  0.315  23.0  0.0\n",
      "\n",
      "[254 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "train_data = pd.read_csv(\"./train_test_data/train.csv\", header = None)\n",
    "test_set = pd.read_csv(\"./train_test_data/test.csv\", header = None)\n",
    "print(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funtions\n",
    "def p_x_given_y(x, mean_y, variance_y):\n",
    "    p = 1/(np.sqrt(2*np.pi*variance_y)) * np.exp((-(x-mean_y)**2)/(2*variance_y))\n",
    "    return p\n",
    "\n",
    "def calulate_posterior(prior_probability,data_list,mean_list,variance_list):\n",
    "    result = prior_probability;\n",
    "    for i in range(len(data_list)):\n",
    "        result = result * p_x_given_y(data_list[i],mean_list[i],variance_list[i])\n",
    "    return result\n",
    "\n",
    "def clasifier(test_entry):\n",
    "    global TN , TP, FP, FN\n",
    "    yes_posterior_prob = calulate_posterior(p_s,test_entry[0:Number_of_features],Yes_mean_list,Yes_Variance_list)\n",
    "    no_posterior_prob = calulate_posterior(p_f,test_entry[0:Number_of_features],No_mean_list,No_Variance_list)\n",
    "    if yes_posterior_prob > no_posterior_prob:\n",
    "        predicted_prob = 1\n",
    "    else:\n",
    "        predicted_prob = 0\n",
    "    if(predicted_prob == 0 and test_entry[Number_of_features]==0):\n",
    "        TN = TN + 1\n",
    "    if(predicted_prob == 1 and test_entry[Number_of_features]==1):\n",
    "        TP = TP + 1\n",
    "    if(predicted_prob == 1 and test_entry[Number_of_features]==0):\n",
    "        FP = FP + 1\n",
    "    if(predicted_prob == 0 and test_entry[Number_of_features]==1):\n",
    "        FN = FN + 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = pd.read_csv(FILE_NAME)\n",
    "# data.hist(figsize=(20, 10));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# msk = np.random.rand(len(data)) < TRAIN_TEST_RATIO\n",
    "\n",
    "# Split into train and test set\n",
    "# train_data = data[msk] \n",
    "# test_set = data[~msk]\n",
    "\n",
    "column_list = train_data.columns.tolist()\n",
    "Number_of_features = len(train_data.columns)-1\n",
    "Outcome_Column = train_data.columns[Number_of_features]\n",
    "\n",
    "data_means = train_data.groupby(Outcome_Column).mean()\n",
    "data_variance = train_data.groupby(Outcome_Column).var()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6614785992217899 0.33852140077821014\n"
     ]
    }
   ],
   "source": [
    "Yes_outcome = 1\n",
    "No_outcome = 0\n",
    "\n",
    "n_f = train_data[Outcome_Column][train_data[Outcome_Column] == No_outcome].count()\n",
    "n_s = train_data[Outcome_Column][train_data[Outcome_Column] == Yes_outcome].count()\n",
    "total = train_data[Outcome_Column].count()\n",
    "\n",
    "# Calculate priors\n",
    "p_f = n_f / total\n",
    "p_s = n_s / total\n",
    "\n",
    "print(p_f, p_s)\n",
    "\n",
    "# Gather stats\n",
    "No_mean_list = list()\n",
    "No_Variance_list = list()\n",
    "Yes_mean_list = list()\n",
    "Yes_Variance_list = list()\n",
    "\n",
    "for x in range(Number_of_features):\n",
    "    No_mean_list.append(data_means[column_list[x]][data_variance.index == No_outcome].values[0])\n",
    "    No_Variance_list.append(data_variance[column_list[x]][data_variance.index == No_outcome].values[0])\n",
    "    Yes_mean_list.append(data_means[column_list[x]][data_variance.index == Yes_outcome].values[0])\n",
    "    Yes_Variance_list.append(data_variance[column_list[x]][data_variance.index == Yes_outcome].values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 0.]\n",
      "[0.33852140077821014, 0.6614785992217899]\n"
     ]
    }
   ],
   "source": [
    "outcome_list = train_data[Outcome_Column].unique()\n",
    "print(outcome_list)\n",
    "\n",
    "# Calculate priors\n",
    "total = train_data[Outcome_Column].count()\n",
    "priors = list()\n",
    "for outcome in outcome_list: \n",
    "    n_outcome = train_data[Outcome_Column][train_data[Outcome_Column] == outcome].count()\n",
    "    priors.append(n_outcome/total)\n",
    "\n",
    "print(priors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Gather stats\n",
    "# def getMeanAndVariance (df, outcome):\n",
    "#     filtered_df = dataset[dataset[classCol] == outcome]\n",
    "#     return [df.mean(axis=0), df.std(axis=0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run model\n",
    "for index,row in test_set.iterrows():\n",
    "    clasifier(row.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix\n",
    "cf_matrix = np.array([[TN, FP], [FN, TP]])\n",
    "group_names = [\"True Neg\",\"False Pos\",\"False Neg\",\"True Pos\"]\n",
    "group_counts = [\"{0:0.0f}\".format(value) for value in\n",
    "                cf_matrix.flatten()]\n",
    "group_percentages = [\"{0:.2%}\".format(value) for value in\n",
    "                     cf_matrix.flatten()/np.sum(cf_matrix)]\n",
    "labels = [f\"{v1}\\n{v2}\\n{v3}\" for v1, v2, v3 in\n",
    "          zip(group_names,group_counts,group_percentages)]\n",
    "labels = np.asarray(labels).reshape(2,2)\n",
    "sns.heatmap(cf_matrix, annot=labels, fmt=\"\", cmap=\"Blues\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = (TP + TN) / (TP + FP + TN +FN)\n",
    "error = (FP + FN) / (TP + FP + TN +FN)\n",
    "sensitivity = TP / (FN + TP)\n",
    "specificity = TN / (TN + FP)\n",
    "\n",
    "report_stats = pd.DataFrame({\n",
    "    \"Accuracy\": [accuracy],\n",
    "    \"Error: \": [error],\n",
    "    \"Sensitivity: \": [sensitivity],\n",
    "    \"Specificity: \": [specificity]\n",
    "})\n",
    "\n",
    "print(report_stats.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Interpretation\\n\")\n",
    "print(f\"The Gaussian model gives us {accuracy * 100:.2f}% accuracy with {error * 100:.2f}% error\\n\")\n",
    "print(f\"Sensitivity shows that this model will correctly return positive result for {sensitivity * 100:.2f}% of people who have the disease and false negative for {(1 - sensitivity) * 100:.2f}% of people who have the disease and should have tested positive.\\n\")\n",
    "print(f\"Specificity shows that this model will correctly return negative result for {specificity * 100:.2f}% of people who don't have the disease and false positive for {(1 - specificity) * 100:.2f}% of people who don't have the disease and should have tested negative.\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
